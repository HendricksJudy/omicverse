{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Domain Research (dr): Comprehensive Report Tutorial\n", "\n", "This notebook shows how to generate a comprehensive report from a user query using `omicverse.llm.domain_research`.\n", "It covers the offline default synthesizer and an optional LLM-backed synthesizer.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> Note: Live Web Retrieval Options\n", "\n", "This tutorial now supports live web-backed retrieval in addition to offline demos.\n", "\n", "- Use `vector_store=\"web\"` to auto-select a backend: Tavily if `TAVILY_API_KEY` is set, otherwise DuckDuckGo.\n", "- Force a backend with `vector_store=\"web:tavily\"` or `\"web:duckduckgo\"`.\n", "- Optional dependencies: `duckduckgo_search` and `beautifulsoup4` improve DuckDuckGo results.\n", "- Set `RUN_WEB`, `RUN_WEB_FORCED`, and/or `RUN_WEB_LLM` to `True` in the cells below to run those examples.\n", "- For LLM-backed synthesis, set `OPENAI_API_KEY`.\n", "- Network access is required for web retrieval and online synthesis.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Quick start (offline)\n", "- Implements a tiny in-memory vector store.\n", "- Uses the default offline synthesizer to build a comprehensive report.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from omicverse.llm.domain_research import ResearchManager\n", "\n", "class DemoStore:\n", "    def search(self, query):\n", "        class Doc:\n", "            def __init__(self, id, text, metadata=None):\n", "                self.id = id\n", "                self.text = text\n", "                self.metadata = metadata\n", "        return [Doc(\"1\", f\"Background on {query} and scRNA-seq workflows.\")]\n", "\n", "rm = ResearchManager(vector_store=DemoStore())\n", "brief = rm.scope(\"Cell type annotation strategies in PBMCs\")\n", "findings = rm.research(brief)\n", "report = rm.write(brief, findings)\n", "print(report[:800])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The generated report includes:\n", "- A top-level \"Comprehensive Report\" section (executive summary + objectives).\n", "- Per-topic sections sourced from the vector store.\n", "- Numbered citations with a \"References\" list appended.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Optional: ChromaDB-backed vector store\n", "If you have `chromadb` and `langchain_community` installed, you can back the vector store with GPT4All embeddings.\n", "This block is safe to run even if dependencies are missing \u2014 it will just skip.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    from omicverse.llm.domain_research import create_store, add_documents, query_store\n", "\n", "    docs = [\"PBMC cell types include T cells, B cells, and monocytes.\",\n", "            \"Leiden clustering identifies cell communities in scRNA-seq.\"]\n", "    collection = create_store(\"demo_dr\", persist_directory=None)\n", "    add_documents(collection, docs, ids=[\"d1\", \"d2\"])\n", "\n", "    class ChromaStore:\n", "        def __init__(self, collection):\n", "            self.collection = collection\n", "        def search(self, query):\n", "            res = query_store(self.collection, query, n_results=2)\n", "            out = []\n", "            for id_, txt in zip(res.get(\"ids\", [[\"\"]])[0], res.get(\"documents\", [[\"\"]])[0]):\n", "                class Doc:\n", "                    pass\n", "                d = Doc(); d.id = id_; d.text = txt; d.metadata = None\n", "                out.append(d)\n", "            return out\n", "\n", "    rm = ResearchManager(vector_store=ChromaStore(collection))\n", "    print(rm.run(\"PBMC annotation best practices\")[:800])\n", "except Exception as e:\n", "    print(\"ChromaDB example skipped:\", e)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Optional: LLM-backed synthesizer (OpenAI-compatible)\n", "Use a chat-completions API to synthesize an executive-style summary.\n", "Set `RUN_ONLINE=True` and ensure `OPENAI_API_KEY` is available.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["RUN_ONLINE = False\n", "if RUN_ONLINE:\n", "    import os\n", "    from omicverse.llm.domain_research.write.synthesizer import PromptSynthesizer\n", "    api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n", "    if not api_key:\n", "        raise RuntimeError(\"Missing OPENAI_API_KEY\")\n", "    synth = PromptSynthesizer(model=\"gpt-4o-mini\", base_url=\"https://api.openai.com/v1\", api_key=api_key)\n", "    rm = ResearchManager(vector_store=DemoStore(), synthesizer=synth)\n", "    print(rm.run(\"Single-cell integration overview\"))\n", "else:\n", "    print(\"RUN_ONLINE is False \u2014 skipped external API calls.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) Optional: Live web search\n", "Use a live web-backed retriever as the vector store.\n", "- If `TAVILY_API_KEY` is set, `vector_store=\"web\"` uses Tavily; otherwise falls back to DuckDuckGo.\n", "- Alternatively, force a backend with `\"web:tavily\"` or `\"web:duckduckgo\"`.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["RUN_WEB = False\n", "if RUN_WEB:\n", "    from omicverse.llm.domain_research import ResearchManager\n", "    # Auto-selects Tavily if TAVILY_API_KEY is present, else DuckDuckGo\n", "    rm = ResearchManager(vector_store=\"web\")\n", "    print(rm.run(\"Recent advances in single-cell RNA-seq batch correction\")[:800])\n", "else:\n", "    print(\"RUN_WEB is False \u2014 skipped live web retrieval.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4a) Force web backend\n", "- Force a specific backend via string flag: `\"web:tavily\"` or `\"web:duckduckgo\"`.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["RUN_WEB_FORCED = False\n", "if RUN_WEB_FORCED:\n", "    from omicverse.llm.domain_research import ResearchManager\n", "    # Force DuckDuckGo (works without API key)\n", "    rm = ResearchManager(vector_store=\"web:duckduckgo\")\n", "    print(rm.run(\"Single-cell clustering best practices\")[:800])\n", "else:\n", "    print(\"RUN_WEB_FORCED is False \u2014 skipped forced backend.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Live web + LLM synthesis\n", "Combine live retrieval with an OpenAI-compatible synthesizer for the executive summary.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["RUN_WEB_LLM = False\n", "if RUN_WEB_LLM:\n", "    import os\n", "    from omicverse.llm.domain_research import ResearchManager\n", "    from omicverse.llm.domain_research.write.synthesizer import PromptSynthesizer\n", "\n", "    api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n", "    if not api_key:\n", "        raise RuntimeError(\"Missing OPENAI_API_KEY\")\n", "    synth = PromptSynthesizer(model=\"gpt-4o-mini\", base_url=\"https://api.openai.com/v1\", api_key=api_key)\n", "    rm = ResearchManager(vector_store=\"web\", synthesizer=synth)\n", "    print(rm.run(\"scRNA-seq batch correction methods in 2024\")[:800])\n", "else:\n", "    print(\"RUN_WEB_LLM is False \u2014 skipped LLM synthesis with web retrieval.\")\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3"}}, "nbformat": 4, "nbformat_minor": 5}