#!/usr/bin/env python3
"""
Phase 3 Runtime Testing - OpenAI Integration

Tests the complete Agent system with real OpenAI API calls to verify:
1. Agent initialization with real API key
2. Skill loading and discovery
3. Actual API calls to OpenAI
4. Skill execution with real LLM responses
5. Provider-specific formatting (OpenAI GPT models)

Run this test with a valid OPENAI_API_KEY environment variable.
"""

import os
import sys
from pathlib import Path

# Add project root to path
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(PROJECT_ROOT))

def test_agent_initialization():
    """Test 1: Agent initializes successfully with real API key"""
    print("\n" + "="*80)
    print("TEST 1: Agent Initialization with Real API Key")
    print("="*80)

    # Verify API key is set
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå OPENAI_API_KEY not set in environment")
        return False

    print(f"‚úÖ API key found: {api_key[:20]}...{api_key[-8:]}")

    try:
        from omicverse.utils.smart_agent import Agent

        # Initialize Agent with GPT-4o-mini (most cost-effective for testing)
        agent = Agent(model="gpt-4o-mini", api_key=api_key)

        print(f"‚úÖ Agent initialized successfully")
        print(f"   Model: {agent.model}")
        print(f"   Provider: {agent.provider}")

        return True

    except Exception as e:
        print(f"‚ùå Agent initialization failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_skill_discovery():
    """Test 2: Verify skills are discovered and loaded correctly"""
    print("\n" + "="*80)
    print("TEST 2: Skill Discovery and Loading")
    print("="*80)

    try:
        from omicverse.utils.smart_agent import Agent
        from omicverse.utils.skill_registry import build_multi_path_skill_registry

        api_key = os.getenv("OPENAI_API_KEY")
        agent = Agent(model="gpt-4o-mini", api_key=api_key)

        # Check if skills were loaded
        package_root = PROJECT_ROOT / "omicverse"
        cwd = Path.cwd()
        registry = build_multi_path_skill_registry(package_root, cwd)

        print(f"‚úÖ Skills discovered: {len(registry.skills)}")

        for slug, skill in registry.skills.items():
            print(f"\n   üìö {skill.name}")
            print(f"      Slug: {slug}")
            print(f"      Path: {skill.path}")
            if skill.description:
                print(f"      Description: {skill.description[:100]}...")

        if len(registry.skills) > 0:
            print(f"\n‚úÖ Skill discovery working correctly")
            return True
        else:
            print(f"\n‚ö†Ô∏è  No skills found (may be expected if none installed)")
            return True  # Not a failure if no skills installed

    except Exception as e:
        print(f"‚ùå Skill discovery failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_simple_api_call():
    """Test 3: Make a simple API call to OpenAI"""
    print("\n" + "="*80)
    print("TEST 3: Simple API Call to OpenAI")
    print("="*80)

    try:
        from omicverse.utils.smart_agent import Agent

        api_key = os.getenv("OPENAI_API_KEY")
        agent = Agent(model="gpt-4o-mini", api_key=api_key)

        # Make a simple test query
        test_prompt = "Say 'Hello from OmicVerse!' if you can read this."

        print(f"üì§ Sending test prompt: '{test_prompt}'")

        response = agent.chat(test_prompt)

        print(f"‚úÖ API call successful")
        print(f"üì• Response: {response}")

        # Verify response contains expected content
        if "hello" in response.lower() or "omicverse" in response.lower():
            print(f"‚úÖ Response content validated")
            return True
        else:
            print(f"‚ö†Ô∏è  Response may not match expected pattern, but API call succeeded")
            return True

    except Exception as e:
        print(f"‚ùå API call failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_provider_formatting():
    """Test 4: Verify provider-specific formatting works"""
    print("\n" + "="*80)
    print("TEST 4: Provider-Specific Formatting")
    print("="*80)

    try:
        from omicverse.utils.skill_instruction_formatter import SkillInstructionFormatter

        # Sample skill content
        sample_skill = """
# Test Skill

This is a test skill to verify formatting.

## Instructions
- Step 1: Do something
- Step 2: Do something else
"""

        # Test OpenAI formatting (should be structured)
        openai_formatted = SkillInstructionFormatter.format_for_provider(
            sample_skill,
            "openai"
        )

        print(f"‚úÖ OpenAI formatting applied")
        print(f"   Length: {len(openai_formatted)} chars (original: {len(sample_skill)})")
        print(f"   Preview:\n{openai_formatted[:200]}...")

        # Verify it's different from original (formatting was applied)
        if openai_formatted != sample_skill:
            print(f"‚úÖ Formatting transformation confirmed")
            return True
        else:
            print(f"‚ö†Ô∏è  Formatting may be minimal (could be expected)")
            return True

    except Exception as e:
        print(f"‚ùå Provider formatting test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_skill_execution():
    """Test 5: Test skill execution with real LLM (if skills available)"""
    print("\n" + "="*80)
    print("TEST 5: Skill Execution with Real LLM")
    print("="*80)

    try:
        from omicverse.utils.smart_agent import Agent
        from omicverse.utils.skill_registry import build_multi_path_skill_registry

        api_key = os.getenv("OPENAI_API_KEY")

        # Check if any skills are available
        package_root = PROJECT_ROOT / "omicverse"
        cwd = Path.cwd()
        registry = build_multi_path_skill_registry(package_root, cwd)

        if len(registry.skills) == 0:
            print("‚ö†Ô∏è  No skills available to test execution")
            print("   (This is OK if no skills are installed)")
            return True

        # If skills available, test with Agent
        agent = Agent(model="gpt-4o-mini", api_key=api_key)

        # Create a prompt that might trigger skill use
        test_prompt = "List the available skills and their purposes."

        print(f"üì§ Testing with prompt: '{test_prompt}'")

        response = agent.chat(test_prompt)

        print(f"‚úÖ Skill-aware API call successful")
        print(f"üì• Response preview: {response[:300]}...")

        return True

    except Exception as e:
        print(f"‚ùå Skill execution test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_model_normalization():
    """Test 6: Verify model ID normalization works with real initialization"""
    print("\n" + "="*80)
    print("TEST 6: Model ID Normalization")
    print("="*80)

    try:
        from omicverse.utils.smart_agent import Agent

        api_key = os.getenv("OPENAI_API_KEY")

        # Test with alias
        print("üîç Testing with alias: 'gpt-4o-mini'")
        agent1 = Agent(model="gpt-4o-mini", api_key=api_key)
        print(f"   Normalized to: {agent1.model}")

        # Test with full ID
        print("üîç Testing with full ID: 'openai/gpt-4o-mini'")
        agent2 = Agent(model="openai/gpt-4o-mini", api_key=api_key)
        print(f"   Normalized to: {agent2.model}")

        print(f"‚úÖ Model normalization working correctly")
        return True

    except Exception as e:
        print(f"‚ùå Model normalization test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """Run all Phase 3 runtime tests"""
    print("\n" + "="*80)
    print("PHASE 3 RUNTIME TESTING - OPENAI INTEGRATION")
    print("="*80)
    print(f"Project Root: {PROJECT_ROOT}")
    print(f"Python: {sys.version}")

    # Verify API key is set
    if not os.getenv("OPENAI_API_KEY"):
        print("\n‚ùå ERROR: OPENAI_API_KEY environment variable not set")
        print("   Please set it before running this test:")
        print("   export OPENAI_API_KEY='your-key-here'")
        return False

    results = {
        "Agent Initialization": test_agent_initialization(),
        "Skill Discovery": test_skill_discovery(),
        "Simple API Call": test_simple_api_call(),
        "Provider Formatting": test_provider_formatting(),
        "Skill Execution": test_skill_execution(),
        "Model Normalization": test_model_normalization(),
    }

    # Summary
    print("\n" + "="*80)
    print("TEST SUMMARY")
    print("="*80)

    total = len(results)
    passed = sum(1 for r in results.values() if r)
    failed = total - passed

    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status}  {test_name}")

    print(f"\n{'='*80}")
    print(f"Results: {passed}/{total} tests passed ({passed/total*100:.1f}%)")

    if failed == 0:
        print("üéâ ALL TESTS PASSED - Phase 3 runtime testing complete!")
        return True
    else:
        print(f"‚ö†Ô∏è  {failed} test(s) failed - see details above")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
